# Databricks for Actuaries: Healthcare Analytics Workshop

This workshop is specifically designed for **actuaries and analysts** familiar with SAS who are new to Databricks, PySpark, and SQL. It provides a hands-on, beginner-friendly introduction to healthcare payer data analytics using Databricks' medallion architecture (Bronze/Silver/Gold layers), with a strong focus on **actuarial use cases**, **data quality**, and **bias detection**.

## ğŸš€ Overview

This interactive workshop guides actuaries through:
- ğŸ“Š **Actuarial-focused analytics**: Loss ratios, claims trending, development triangles, frequency/severity
- ğŸ” **Data quality checks**: Completeness, accuracy, duplicates, and validation
- âš–ï¸ **Bias detection**: Demographic, geographic, temporal, and provider bias analysis
- ğŸ’» **SAS to Databricks translation**: Side-by-side comparisons of familiar SAS procedures
- ğŸ¯ **Simple SQL approach**: Minimal PySpark, maximum hands-on exercises
- ğŸ“ˆ **Regulatory compliance**: Meeting ASOP and ACA anti-discrimination requirements


## ğŸ“‚ Medallion Architecture (Simplified for Actuaries)

- **Bronze Layer (Quick Setup):** Raw data ingestion from CSV files using `COPY INTO` - streamlined for fast setup
- **Silver Layer (Quick Setup):** Basic cleaning and type corrections - get to analytics quickly!
- **Gold Layer (Main Focus ğŸ‰):** Deep actuarial analytics, interactive exercises, and business insights

This modular pattern ensures data lineage, scalability, and aligns with actuarial workflow requirements.

## ğŸ—ï¸ Features

### ğŸ¯ Actuarial Analytics Exercises
- **Loss Ratio Analysis**: Calculate loss ratios by specialty, state, and plan type
- **Claims Trending**: Month-over-month and year-over-year growth analysis using window functions
- **Development Triangles**: Claims emergence patterns for reserving (IBNR indicators)
- **Frequency & Severity**: Risk segmentation and pricing metrics
- **High-Risk Member Identification**: Using percentile analysis (95th, 99th)

### ğŸ” Data Quality & Compliance
- **Completeness Checks**: Identify missing critical fields
- **Accuracy Validation**: Detect negative amounts, future dates, zero-dollar claims
- **Duplicate Detection**: Find and quantify duplicate records
- **Bias Detection**: Demographic, geographic, temporal, and provider bias analysis
- **Regulatory Compliance**: ASOP and ACA anti-discrimination requirements

### ğŸ’» SAS User-Friendly
- **Side-by-side SAS comparisons**: `PROC SQL`, `PROC MEANS`, `PROC FREQ`, `DATA` steps
- **Familiar concepts**: LAG functions, window functions, percentiles, rolling averages
- **Simple SQL focus**: Minimal PySpark, beginner-friendly syntax
- **Interactive exercises**: Hands-on learning with starter code and hints

### ğŸ› ï¸ Technical Features
- **Databricks Unity Catalog**: Modern data governance and organization
- **Delta Lake**: ACID transactions, time travel, and data versioning
- **Parameterized setup**: Reusable for different environments
- **Synthetic demo data**: Realistic healthcare payer data for safe training

## ğŸ“ How to Use This Workshop

### For Workshop Participants (Actuaries & Analysts)
1. **Import the notebook** to your Databricks workspace
2. **Part 1 (Quick Setup - 10 mins)**: Run Bronze/Silver cells to load data
   - Just execute the cells - they're simplified!
   - Creates your working datasets
3. **Part 2 (The Fun Part! ğŸ‰ - 1.5 hours)**: Gold Layer Actuarial Analytics
   - Work through 6 interactive exercises
   - Compare SAS vs Databricks approaches
   - Build actuarial analytics tables
   - Detect data quality issues and bias
4. **Explore and experiment**: Modify queries, try your own analyses


## ğŸ“‹ Healthcare Payer Data Model

**Datasets (Bronze â†’ Silver â†’ Gold):**
- **Members**: Policy data (demographics, plan info, enrollment dates)
- **Claims**: Incurred losses (amounts, dates, provider info)
- **Providers**: Network data (specialty, location, credentials)
- **Diagnoses**: ICD codes linked to claims
- **Procedures**: CPT/HCPCS codes and charges

**Gold Layer Analytics Tables Created:**
- `loss_ratios_by_segment`: Loss ratios by specialty and state
- `claims_trend_analysis`: Monthly trending with MoM/YoY growth
- `claims_development`: Development triangles for reserving

## ğŸ’¡ Actuarial Use Cases Covered

### Pricing & Underwriting
- Loss ratio analysis by segment (specialty, geography, plan)
- Frequency and severity decomposition
- Risk segmentation and tiering
- Provider network cost analysis

### Reserving & Forecasting
- Claims development patterns (emergence analysis)
- IBNR indicators and completeness checks
- Monthly trend analysis with seasonality
- Age-to-age development factors

### Data Quality & Compliance
- Completeness validation (missing data detection)
- Accuracy checks (negative amounts, future dates)
- Duplicate claim detection
- Bias detection for regulatory compliance (ACA, ASOP)

### Risk Management
- High-risk member identification
- Provider outlier detection (potential fraud/error)
- Geographic and demographic bias analysis
- Temporal completeness monitoring


## ğŸ› ï¸ Getting Started

### Quick Start (5 minutes)

**In Databricks:**
1. In your Databricks *Free Edition* workspace, create new **Git folder** and paste the following github link https://github.com/bigdatavik/databricksfirststeps.git
2. Run cells sequentially - start with Part 1 (Setup), then move to Part 2 (Analytics)
3. Work through the interactive exercises at your own pace!


## ğŸ“‘ Project Structure

```
â”œâ”€â”€ DBX Workshop_IPA Actuaries_10262025.ipynb    â­ Main actuarial workshop
â”œâ”€â”€ [Dashboard] Actuarial Analytics              â­ Reference dashboard
â”œâ”€â”€ [Reference] Best Practices                   â­ Reference best practices
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ claims.csv                                 ğŸ’° Medical claim submissions
â”‚   â”œâ”€â”€ diagnoses.csv                             ğŸ¥ Diagnosis codes from claims
â”‚   â”œâ”€â”€ procedures.csv                            ğŸ”¬ Medical procedures performed
â”‚   â”œâ”€â”€ providers.csv                             ğŸ‘¨â€âš•ï¸ Healthcare providers
â”‚   â”œâ”€â”€ member.csv                                 ğŸ‘¥ Health plan enrollees
â”‚   â””â”€â”€ Payor_Archive.zip
â”œâ”€â”€ past labs/
â”‚   â”œâ”€â”€ DBSQL_Workshop_ETL and Analytics_10072025.ipynb  (Original version)
â”‚   â””â”€â”€ ...
â”œâ”€â”€ README.md                                      ğŸ“– This file
â””â”€â”€ LICENSE.md
```

---

### Â© 2025 | Designed for actuaries, analysts, and healthcare data professionals
**Target Audience:** Actuaries and analysts transitioning from SAS to Databricks  
**Workshop Duration:** 2 hours (hands-on)  
**Difficulty Level:** Beginner-friendly with intermediate analytics concepts  

*Last updated: November 7, 2025*